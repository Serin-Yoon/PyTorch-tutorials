{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "_WH5NciOSz6Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor Initialization**"
      ],
      "metadata": {
        "id": "8yenwDmbVcCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 1: Directly from data\n",
        "\n",
        "data = [[1, 2], [3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "4kXzRBdGUM6b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 2: From a NumPy array\n",
        "\n",
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "xUtpYFfKVldW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 3: From another tensor\n",
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Rensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "id": "E3CyCdxfVmwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Method 4: With random or constant values\n",
        "\n",
        "shape = (2, 3,) # tuple of tensor dimensions\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "metadata": {
        "id": "J1PLyZk4VoEp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor Attributes**"
      ],
      "metadata": {
        "id": "nFEPw08gV3Vk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Describe their shape, datatype, and the device on which they are stored.\n",
        "\n",
        "tensor = torch.rand(3, 4)\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "id": "TkmlXiwWV5DV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor Operations**\n",
        "- transposing, indexing, slicing, mathematical operations, linear algebra, random sampling, ...\n",
        "- https://pytorch.org/docs/stable/torch.html"
      ],
      "metadata": {
        "id": "et0YXEy4WTaR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Move our tensor to the GPU if available (if using Colab just change settings)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to('cuda')\n",
        "  print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "id": "NJVe61J6WRZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard numpy-like indexing and slicing\n",
        "\n",
        "tensor = torch.ones(4, 4)\n",
        "tensor[:, 1] = 0\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "7FhLyPTDXVVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Joining tensors\n",
        "\n",
        "# use torch.cat to concatenate a sequence of tensors along a given dimension\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "id": "njBqS7maX1dW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Multiplying tensors\n",
        "\n",
        "# computes element-wise product\n",
        "print(f\"tensor.mul(tensor) \\n {tensor.mul(tensor)} \\n\")\n",
        "print(f\"tensor * tensor \\n {tensor * tensor}\\n\")\n",
        "\n",
        "# computes matrix multiplication between two tensors\n",
        "print(f\"tensor.matmul(tensor.T) \\n {tensor.matmul(tensor.T)} \\n\")\n",
        "print(f\"tensor @ tensor.T \\n {tensor @ tensor.T}\")"
      ],
      "metadata": {
        "id": "dYE6W9BBYKXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# In-place operations\n",
        "# in-place: operations that have a _ suffix\n",
        "\n",
        "print(tensor, \"\\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "metadata": {
        "id": "FdkvtNPvYwj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Bridge with NumPy**\n",
        "- Tensors on the CPU and NumPy arrays can share their underlying memory locations, and changing one will change another."
      ],
      "metadata": {
        "id": "KT2cc4pnZoBB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tensor to NumPy array**"
      ],
      "metadata": {
        "id": "sUi4KzS_Z1Sc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n = t.numpy()\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "id": "wgQEPd06Zzu7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change in the tensor reflects in the NumPy array\n",
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "id": "4A1-qnJiitOX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NumPy array to Tensor**"
      ],
      "metadata": {
        "id": "qqhBytq-i1Xt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n = np.ones(5)\n",
        "t = torch.from_numpy(n)"
      ],
      "metadata": {
        "id": "iZDidesIi32l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# change in the NumPy array reflects in the tensor\n",
        "np.add(n, 1, out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "id": "eGY8zZfJi8xX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}